{
  "schema_version": 1,
  "created_at": "2026-02-21T23:57:12.197612+00:00",
  "optimization_id": "0.5",
  "seed": 42,
  "tasks_per_arm": 50,
  "workload_pack_path": "/mnt/raid0/llm/epyc-inference-research/benchmarks/root_workload/workload_pack_curated_debug_hard50_v1.json",
  "workload_pack_version": "curated-debug-hard50-v1",
  "selected_tasks": [
    {
      "task_id": "agentic_007_bfcl_026",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef deploy_container(image: str, name: str, ports: dict = None, volumes: dict = None, env: dict = None) -> str:\n    \"\"\"Deploy a container.\"\"\"\n\ndef scale_service(service_name: str, replicas: int) -> bool:\n    \"\"\"Scale service replicas.\"\"\"\n```\n\nLaunch a Redis container named \"cache-01\" mapping port 6379 to\nhost port 6380, mounting /data/redis to /data in the container.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_026",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_026",
      "expected": "deploy_container",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_008_ma_hard_code_013",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Hopcroft-Karp algorithm for maximum bipartite matching.\n\nGiven a bipartite graph with left vertices 0..n-1 and right vertices 0..m-1,\nand a list of edges, find the maximum matching.\n\nReturn:\n- Size of maximum matching\n- List of (left, right) pairs in the matching\n\nTime complexity should be O(E\u221aV).\n\nWrite `def hopcroft_karp(n, m, edges)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_013",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_013",
      "expected": "def hopcroft_karp",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_002_code_hard_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `eval_rpn(tokens)` that evaluates a\nmathematical expression in Reverse Polish Notation. The tokens are\na list of strings, where each string is either an integer or one of\n'+', '-', '*', '/'. Division truncates toward zero.\n\n>>> eval_rpn([\"2\", \"1\", \"+\", \"3\", \"*\"])\n9\n>>> eval_rpn([\"4\", \"13\", \"5\", \"/\", \"+\"])\n6\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_002",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_003_ma_hard_code_003",
      "task_class": "implementation_fix",
      "input_payload": "Implement Tarjan's algorithm for finding strongly connected components\nin a directed graph.\n\nGiven:\n- N nodes numbered 0 to N-1\n- List of edges as (from, to) tuples\n\nReturn:\n- List of SCCs, where each SCC is a list of node indices\n- SCCs should be in reverse topological order\n\nExample:\nedges = [(0,1), (1,2), (2,0), (1,3), (3,4), (4,5), (5,3)]\nExpected output: [[3,4,5], [0,1,2]]\n\nWrite a complete Python function `find_sccs(n, edges)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_003",
      "expected": "def find_sccs",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_010_coder_ma_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function that converts a Roman numeral string to an integer.\nSupport I, V, X, L, C, D, M (values 1 to 3999).\n\n```python\ndef roman_to_int(s):\n    \"\"\"Convert Roman numeral string to integer.\"\"\"\n    pass\n```\n\nWrite the complete function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_002",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_001_agentic_ma_002",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  search_database(query: str, table: str) -> list[dict]\n  aggregate(data: list[dict], group_by: str, metric: str) -> dict\n  format_report(title: str, data: dict, format: str) -> str\n  send_email(to: str, subject: str, body: str) -> bool\n\nTask: Generate a monthly sales report.\n1. Search the \"orders\" table for all orders in January 2024\n2. Aggregate the results by \"product_category\" using metric \"sum:total_amount\"\n3. Format the aggregated data as an HTML report titled \"January 2024 Sales\"\n4. Email the report to \"manager@company.com\" with subject \"Monthly Sales Report\"\n\nShow all 4 tool calls in order as JSON.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_002",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_002",
      "expected": "search_database",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_004_code_hard_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `longest_palindromic_substring(s)` that finds\nthe longest palindromic substring in s.\n\n>>> longest_palindromic_substring(\"babad\")\n\"bab\"  # or \"aba\"\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_004",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_006_ma_hard_code_009",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Hungarian algorithm for the assignment problem.\n\nGiven an N\u00d7N cost matrix, find the assignment of workers to jobs\nthat minimizes total cost. Each worker is assigned exactly one job\nand each job is assigned exactly one worker.\n\nReturn the minimum total cost and the assignment as a list where\nassignment[i] is the job assigned to worker i.\n\nExample:\ncost = [[9, 2, 7, 8],\n        [6, 4, 3, 7],\n        [5, 8, 1, 8],\n        [7, 6, 9, 4]]\nExpected minimum cost: 13 (assignments: 0\u21921, 1\u21922, 2\u21922... wait)\n\nWrite `def hungarian(cost_matrix)` returning (min_cost, assignment).\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_009",
      "expected": "def hungarian",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_002_ma_hard_code_002",
      "task_class": "implementation_fix",
      "input_payload": "Implement a lock-free stack using compare-and-swap (CAS) operations.\n\nThe stack must handle the ABA problem correctly using either:\n1. Hazard pointers, or\n2. Tagged pointers with version numbers\n\nRequirements:\n- push(value): Add value to top of stack\n- pop(): Remove and return top value, or None if empty\n- Must be thread-safe without using locks\n\nWrite a Python implementation using atomics from the `atomics` library\nor simulate CAS with a lock for demonstration purposes.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_002",
      "expected": "class LockFreeStack",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_009_ma_hard_code_015",
      "task_class": "implementation_fix",
      "input_payload": "Implement a suffix array construction algorithm with O(n log n) complexity.\n\nGiven a string s, compute:\n1. The suffix array (indices of sorted suffixes)\n2. The LCP (Longest Common Prefix) array\n\nExample:\ns = \"banana\"\nsuffix_array = [5, 3, 1, 0, 4, 2]\n(suffixes: \"a\", \"ana\", \"anana\", \"banana\", \"na\", \"nana\" sorted)\nlcp_array = [1, 3, 0, 0, 2]\n\nWrite `def build_suffix_array(s)` returning (suffix_array, lcp_array).\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_015",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_015",
      "expected": "def build_suffix_array",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_013_code_hard_011",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `group_anagrams(words)` that takes a list of\nstrings and groups anagrams together. Return a list of lists, where\neach inner list contains words that are anagrams of each other.\nOrder within groups doesn't matter.\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_011",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_011",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_003_code_hard_003",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `min_window(s, t)` that finds the minimum\nwindow substring of s that contains all characters of t. Return \"\"\nif no such window exists.\n\n>>> min_window(\"ADOBECODEBANC\", \"ABC\")\n\"BANC\"\n>>> min_window(\"a\", \"aa\")\n\"\"\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_003",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_005_logic_004",
      "task_class": "planning_synthesis",
      "input_payload": "Five people finished a race. Amy finished before Ben. Charlie\nfinished after Diana. Ben finished before Diana. Evan finished\nlast. What is the minimum possible position for Charlie?\n\nA) 2nd\nB) 3rd\nC) 4th\nD) 5th\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_004",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_004",
      "expected": "C",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "long_context_004_needle_007",
      "task_class": "long_input",
      "input_payload": "Read these three interconnected reports.\n\n=== REPORT A: Sales Summary ===\nQ1 2025 sales by region:\n- North America: $15.3M (lead: Sarah Johnson)\n- Europe: $12.1M (lead: Marco Rossi)\n- Asia Pacific: $18.7M (lead: Yuki Tanaka)\nTotal Q1 2025: $46.1M\n\n=== REPORT B: Regional Strategy ===\nThe highest-performing region in Q1 should receive an additional\n20% budget increase for Q2. The regional lead of the\nhighest-performing region will present at the annual conference.\n\n=== REPORT C: Conference Details ===\nAnnual Sales Conference: July 15-17, 2025, Grand Hotel, Singapore.\nKeynote speaker: CEO Maria Garcia.\nRegional presentation slot: Day 2, 10:00 AM.\n\nQuestion: Based on Q1 2025 performance, who will present at the\nannual conference and in which city will it be held?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_007",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_007",
      "expected": "Yuki Tanaka",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_007_ma_hard_code_011",
      "task_class": "implementation_fix",
      "input_payload": "Implement Dijkstra's algorithm with a Fibonacci heap for O(E + V log V)\ncomplexity. If Fibonacci heap is too complex, use a standard heap but\ndocument the complexity difference.\n\nGiven:\n- Number of vertices V\n- List of edges as (u, v, weight) tuples\n- Source vertex s\n\nReturn:\n- Dictionary mapping each vertex to its shortest distance from s\n- Dictionary mapping each vertex to its predecessor in the shortest path\n\nWrite `def dijkstra(V, edges, source)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_011",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_011",
      "expected": "def dijkstra",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_004_bfcl_009",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these functions:\n\n```\ndef read_file(path: str) -> str:\n    \"\"\"Read a file's contents.\"\"\"\n\ndef write_file(path: str, content: str) -> bool:\n    \"\"\"Write content to a file.\"\"\"\n\ndef list_directory(path: str, recursive: bool = False) -> list:\n    \"\"\"List files in a directory.\"\"\"\n\ndef execute_command(command: str, timeout: int = 30) -> dict:\n    \"\"\"Execute a shell command.\"\"\"\n```\n\nThe user says: \"List all Python files in the project directory at\n/home/user/project, including subdirectories.\"\n\nChoose the correct function and respond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_009",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_009",
      "expected": "list_directory",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_005_code_hard_005",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `permutations(lst)` that generates all\npermutations of a list. Return as a list of lists.\n\n>>> sorted(permutations([1, 2, 3]))\n[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]]\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_005",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_003_needle_006",
      "task_class": "long_input",
      "input_payload": "Read the following company documents carefully. You will need to\ncombine information from multiple sections.\n\n=== DOCUMENT 1: Employee Directory ===\n- Alice Chen: Engineering Manager, Team Alpha, Office 301\n- Bob Kumar: Senior Engineer, Team Beta, Office 412\n- Carol Davis: Product Manager, Team Alpha, Office 303\n- David Lee: Junior Engineer, Team Alpha, Office 305\n- Eve Wilson: Senior Engineer, Team Alpha, Office 302\n\n=== DOCUMENT 2: Team Assignments ===\nTeam Alpha is working on Project Phoenix. The team lead is Alice Chen.\nTeam Beta is working on Project Mercury. The team lead is Frank Martinez.\nProject Phoenix has a deadline of March 2026.\nProject Mercury has a deadline of June 2026.\n\n=== DOCUMENT 3: Budget Allocations ===\nProject Phoenix: $1.2M (Q1: $400K, Q2: $500K, Q3: $300K)\nProject Mercury: $800K (Q1: $300K, Q2: $300K, Q3: $200K)\nThe Project Phoenix technical reviewer is Eve Wilson.\n\nQuestion: Who is the technical reviewer for the project that\nDavid Lee is working on, and what is that project's Q2 budget?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_006",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_006",
      "expected": "Eve Wilson",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_011_coder_ma_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function that checks if a given sudoku board is valid.\nThe board is a 9x9 list of lists, with 0 representing empty cells.\nCheck rows, columns, and 3x3 sub-boxes.\n\n```python\ndef is_valid_sudoku(board):\n    \"\"\"Return True if the board state is valid (no conflicts).\"\"\"\n    pass\n```\n\nWrite the complete function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_004",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_009_bfcl_028",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef create_alert(name: str, condition: str, actions: list, severity: str = \"warning\") -> int:\n    \"\"\"Create monitoring alert.\"\"\"\n\ndef create_dashboard(name: str, widgets: list, refresh_interval: int = 60) -> int:\n    \"\"\"Create monitoring dashboard.\"\"\"\n```\n\nSet up a critical alert named \"High CPU\" that triggers when CPU\nexceeds 90% for 5 minutes, sending notifications to #ops channel.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_028",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_028",
      "expected": "create_alert",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "long_context_001_lc_ma_002",
      "task_class": "long_input",
      "input_payload": "Read the following employee database and answer the multi-hop question.\n\nEMPLOYEES:\n| ID  | Name          | Dept    | Manager_ID | Salary | Hire_Date  |\n|-----|---------------|---------|------------|--------|------------|\n| 101 | Sarah Chen    | Eng     | 105        | 125000 | 2019-03-15 |\n| 102 | James Wilson  | Eng     | 105        | 115000 | 2020-06-01 |\n| 103 | Maria Garcia  | Sales   | 106        | 95000  | 2018-11-20 |\n| 104 | David Kim     | Sales   | 106        | 88000  | 2021-01-10 |\n| 105 | Lisa Park     | Eng     | 110        | 155000 | 2015-08-01 |\n| 106 | Tom Brown     | Sales   | 110        | 140000 | 2016-04-22 |\n| 107 | Amy Johnson   | Eng     | 105        | 108000 | 2022-09-15 |\n| 108 | Carlos Ruiz   | HR      | 110        | 98000  | 2019-07-01 |\n| 109 | Priya Patel   | HR      | 108        | 82000  | 2021-03-01 |\n| 110 | Robert Taylor | Exec    | NULL       | 200000 | 2012-01-15 |\n| 111 | Wei Zhang     | Eng     | 105        | 120000 | 2020-02-01 |\n| 112 | Anna Schmidt  | Sales   | 106        | 91000  | 2022-05-10 |\n\nMulti-hop question: What is the total salary of all employees whose manager\nreports directly to Robert Taylor (ID 110)? Do NOT include the managers\nthemselves or Robert Taylor.\n\nGive the total salary after ####.\n",
      "quality_rubric_id": "rubric.debug.long_context.lc_ma_002",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "lc_ma_002",
      "expected": "824000",
      "tier": 3,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "thinking_004_logic_003",
      "task_class": "planning_synthesis",
      "input_payload": "In a room there are 3 people: Alice, Bob, and Charlie. Exactly one\nof them is lying. Alice says: \"Bob is lying.\" Bob says: \"Charlie is\nlying.\" Charlie says: \"Alice is lying.\"\n\nWho is telling the truth?\n\nA) Only Alice\nB) Only Bob\nC) Only Charlie\nD) Exactly two of them are telling the truth\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_003",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_003",
      "expected": "D",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "mode_advantage_hard_014_ma_hard_code_012",
      "task_class": "implementation_fix",
      "input_payload": "Implement a Bloom filter with the following interface:\n\nclass BloomFilter:\n    def __init__(self, capacity: int, error_rate: float):\n        # Initialize with expected capacity and desired false positive rate\n\n    def add(self, item: str) -> None:\n        # Add an item to the filter\n\n    def __contains__(self, item: str) -> bool:\n        # Return True if item might be in set, False if definitely not\n\nUse optimal number of hash functions: k = (m/n) * ln(2)\nwhere m = bits, n = capacity.\n\nWrite a complete Python implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_012",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_012",
      "expected": "class BloomFilter",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_012_code_hard_010",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `is_balanced(s)` that checks if a string\ncontaining only '(', ')', '{', '}', '[', ']' has balanced brackets.\nReturn True if balanced, False otherwise.\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_010",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_005_needle_008",
      "task_class": "long_input",
      "input_payload": "Read the following technical specifications.\n\n=== SERVER RACK A (Floor 3) ===\nSlot 1: Web server (nginx), IP: 10.0.1.101, Status: Active\nSlot 2: Application server (node.js), IP: 10.0.1.102, Status: Active\nSlot 3: Cache server (Redis), IP: 10.0.1.103, Status: Maintenance\nSlot 4: Empty\n\n=== SERVER RACK B (Floor 5) ===\nSlot 1: Database primary (PostgreSQL), IP: 10.0.2.201, Status: Active\nSlot 2: Database replica (PostgreSQL), IP: 10.0.2.202, Status: Active\nSlot 3: Search engine (Elasticsearch), IP: 10.0.2.203, Status: Active\nSlot 4: Message queue (RabbitMQ), IP: 10.0.2.204, Status: Active\n\n=== NETWORK POLICY ===\nAll maintenance-status servers must be rebooted before the\nmonthly security scan on the 1st of each month. The network\nadministrator for Floor 3 is James Park (ext. 4455). The network\nadministrator for Floor 5 is Lisa Wang (ext. 4466).\n\nQuestion: Which server needs to be rebooted before the security scan,\nwhat is its IP address, and who is the responsible administrator?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_008",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_008",
      "expected": "10.0.1.103",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "long_context_002_lc_ma_004",
      "task_class": "long_input",
      "input_payload": "Read the following research paper abstracts and determine which claims\nare supported, contradicted, or unaddressed across all three papers.\n\nPaper A (Chen et al., 2023): \"We demonstrate that transformer models\nwith more than 10B parameters show emergent chain-of-thought reasoning\non mathematical tasks, achieving 78% accuracy on GSM8K without explicit\nCoT prompting. Models below 3B parameters showed no such emergence.\nFine-tuning on synthetic math data improved results by 12 percentage\npoints across all model sizes.\"\n\nPaper B (Williams & Patel, 2024): \"Our analysis reveals that apparent\n'emergent' abilities in large language models are largely artifacts of\ndiscrete evaluation metrics. When using continuous metrics, performance\nscales smoothly with model size. However, we confirm that models above\n7B parameters do show qualitatively different reasoning patterns on\nmulti-step math tasks compared to smaller models.\"\n\nPaper C (Nakamura et al., 2024): \"We replicate the findings of Chen et\nal. on mathematical reasoning emergence but find the threshold to be 7B\nparameters rather than 10B when using improved training data. Our models\nat 7B achieve 82% on GSM8K. We also find that fine-tuning gains are\ninversely proportional to model size, contradicting Chen et al.'s\nfinding of uniform improvement.\"\n\nFor each claim, state: SUPPORTED, CONTRADICTED, or MIXED\n1. Emergence requires >10B parameters\n2. Fine-tuning provides uniform improvement across sizes\n3. Larger models show different reasoning patterns\n\nFormat: \"1: X, 2: Y, 3: Z\"\nGive your answer after ####.\n",
      "quality_rubric_id": "rubric.debug.long_context.lc_ma_004",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "lc_ma_004",
      "expected": "1: CONTRADICTED, 2: CONTRADICTED, 3: SUPPORTED",
      "tier": 3,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "coder_015_coder_ma_003",
      "task_class": "implementation_fix",
      "input_payload": "What does this code print? Trace through carefully.\n\n```python\ndef f(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n <= 1:\n        return n\n    memo[n] = f(n-1, memo) + f(n-2, memo)\n    return memo[n]\n\nresults = []\nfor x in [10, 5, 15]:\n    results.append(f(x))\nprint(results[0], results[1], results[2])\n```\n\nGive the exact output after ####.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_003",
      "expected": "55 5 610",
      "tier": 2,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "agentic_010_bfcl_029",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef execute_workflow(workflow_def: dict, inputs: dict, options: dict = None) -> str:\n    \"\"\"Execute multi-step workflow.\"\"\"\n```\n\nRun a workflow: 1) pull latest code, 2) run tests, 3) build docker\nimage if tests pass, 4) deploy to staging, with 30-min timeout.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_029",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_029",
      "expected": "execute_workflow",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_004_ma_hard_code_005",
      "task_class": "implementation_fix",
      "input_payload": "Implement a segment tree with lazy propagation that supports:\n1. Range update: Add value v to all elements in range [l, r]\n2. Range query: Find sum of elements in range [l, r]\n\nBoth operations must be O(log n).\n\nExample:\narr = [1, 3, 5, 7, 9, 11]\ntree = SegmentTree(arr)\ntree.range_query(1, 3)  # Returns 15 (3+5+7)\ntree.range_update(1, 3, 10)  # Add 10 to indices 1,2,3\ntree.range_query(1, 3)  # Returns 45 (13+15+17)\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_005",
      "expected": "class SegmentTree",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_012_ma_hard_code_008",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Floyd-Warshall algorithm for all-pairs shortest paths.\n\nGiven an adjacency matrix where matrix[i][j] is the weight of edge i\u2192j\n(or float('inf') if no edge), compute the shortest path between all pairs.\n\nAlso detect if there's a negative cycle (return None in that case).\n\nExample:\nmatrix = [\n  [0, 3, float('inf'), 5],\n  [2, 0, float('inf'), 4],\n  [float('inf'), 1, 0, float('inf')],\n  [float('inf'), float('inf'), 2, 0]\n]\n\nWrite `def floyd_warshall(matrix)` returning the distance matrix.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_008",
      "expected": "def floyd_warshall",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_001_ma_hard_code_001",
      "task_class": "implementation_fix",
      "input_payload": "Implement a solution for the following problem:\n\nGiven a weighted directed graph with N nodes (1 to N) and M edges,\nfind the shortest path from node 1 to node N that uses at most K edges.\nIf no such path exists, return -1.\n\nInput format:\n- First line: N M K\n- Next M lines: u v w (edge from u to v with weight w)\n\nExample:\nInput:\n4 5 2\n1 2 1\n1 3 5\n2 3 1\n2 4 10\n3 4 1\n\nOutput: 3\n(Path: 1\u21922\u21923\u21924 with total weight 3, using 3 edges... wait, that's 3 edges.\n With K=2: 1\u21923\u21924 = 6, 1\u21922\u21924 = 11. Answer should be 6)\n\nActually output: 6\n\nWrite a complete Python solution.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_001",
      "expected": "def solve",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_005_ma_hard_code_007",
      "task_class": "implementation_fix",
      "input_payload": "Implement a Treap (tree + heap) data structure with:\n1. insert(key, priority): Insert a key with given priority\n2. delete(key): Remove a key from the treap\n3. search(key): Return True if key exists\n4. The tree must maintain BST property on keys and max-heap on priorities\n\nRotations must be used to maintain the heap property.\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_007",
      "expected": "class Treap",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_015_ma_hard_code_014",
      "task_class": "implementation_fix",
      "input_payload": "Implement a LRU (Least Recently Used) cache with O(1) operations:\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        pass\n\n    def get(self, key: int) -> int:\n        # Return value if exists, -1 otherwise\n        # Mark as recently used\n\n    def put(self, key: int, value: int) -> None:\n        # Insert or update key-value\n        # Evict LRU item if at capacity\n\nMust use O(1) time for both get and put.\n\nWrite a complete Python implementation using OrderedDict or\na combination of dict and doubly-linked list.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_014",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_014",
      "expected": "class LRUCache",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_003_arc_020",
      "task_class": "planning_synthesis",
      "input_payload": "In molecular biology, what is the role of the TATA box?\n\nA) It codes for transfer RNA\nB) It is a promoter sequence for transcription initiation\nC) It signals translation termination\nD) It binds ribosomes directly\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.arc_020",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "arc_020",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "mode_advantage_hard_010_ma_hard_code_004",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Aho-Corasick algorithm for multiple pattern matching.\n\nGiven a text and a list of patterns, find all occurrences of any pattern\nin the text. Return a list of (pattern_index, start_position) tuples.\n\nExample:\ntext = \"ushers\"\npatterns = [\"he\", \"she\", \"his\", \"hers\"]\nExpected: [(1, 1), (0, 2), (3, 2)]\n(she at pos 1, he at pos 2, hers at pos 2)\n\nWrite a complete Python implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_004",
      "expected": "def aho_corasick",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_006_bfcl_025",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef create_backup(sources: list, destination: str, options: dict = None) -> str:\n    \"\"\"Create backup archive.\n    Args:\n        sources: List of paths to backup\n        destination: Backup destination path\n        options: Backup options (exclude_patterns, compression, incremental, encryption)\n    \"\"\"\n```\n\nCreate an incremental encrypted backup of /home and /etc to\n/backup/daily.tar.gz, excluding .cache and .tmp directories.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_025",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_025",
      "expected": "create_backup",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_008_bfcl_027",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef analyze_logs(log_path: str, filters: dict, aggregations: list, time_range: dict = None) -> dict:\n    \"\"\"Analyze log files with complex queries.\"\"\"\n```\n\nAnalyze /var/log/nginx/access.log for the last 24 hours, counting\nrequests by HTTP status code, filtering out health check endpoints.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_027",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_027",
      "expected": "analyze_logs",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "thinking_002_arc_019",
      "task_class": "planning_synthesis",
      "input_payload": "Which particle mediates the electromagnetic force in quantum field theory?\n\nA) Gluon\nB) Photon\nC) W boson\nD) Graviton\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.arc_019",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "arc_019",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "mode_advantage_hard_013_ma_hard_code_010",
      "task_class": "implementation_fix",
      "input_payload": "Implement a trie (prefix tree) with the following methods:\n1. insert(word): Add a word to the trie\n2. search(word): Return True if word exists\n3. starts_with(prefix): Return True if any word starts with prefix\n4. autocomplete(prefix, limit): Return up to `limit` words with given prefix\n\nThe autocomplete should return words in lexicographic order.\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_010",
      "expected": "class Trie",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_001_code_hard_001",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `longest_common_subsequence(s1, s2)` that\nreturns the length of the longest common subsequence of two strings.\n\n>>> longest_common_subsequence(\"abcde\", \"ace\")\n3\n>>> longest_common_subsequence(\"abc\", \"def\")\n0\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_001",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_009_code_hard_009",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `matrix_multiply(A, B)` that multiplies two\nmatrices represented as lists of lists. Return the resulting matrix.\nAssume dimensions are compatible (A is m\u00d7n, B is n\u00d7p).\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_009",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_014_coder_ma_001",
      "task_class": "implementation_fix",
      "input_payload": "The following function is supposed to implement run-length encoding\nbut produces wrong output. Fix it.\n\n```python\ndef rle_encode(s):\n    if not s:\n        return \"\"\n    result = []\n    count = 1\n    for i in range(1, len(s)):\n        if s[i] == s[i-1]:\n            count += 1\n        else:\n            result.append(f\"{count}{s[i]}\")\n            count = 1\n    result.append(f\"{count}{s[-1]}\")\n    return \"\".join(result)\n```\n\nWrite the corrected function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_001",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_003_bfcl_008",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n```\ndef query_database(table: str, conditions: dict, columns: list = [], limit: int = 100) -> list:\n    \"\"\"Query a database table.\n    Args:\n        table: Table name\n        conditions: WHERE conditions as key-value pairs\n        columns: Columns to select (empty = all)\n        limit: Max rows to return\n    \"\"\"\n```\n\nFind the first 5 users from the \"users\" table who are located in\n\"New York\" and have status \"active\". Only return their name and email.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_008",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_008",
      "expected": "query_database",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_006_code_hard_006",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `quick_sort(lst)` that implements the quicksort\nalgorithm to sort a list of numbers in ascending order.\n\n>>> quick_sort([3, 6, 8, 10, 1, 2, 1])\n[1, 1, 2, 3, 6, 8, 10]\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_006",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_002_agentic_ma_004",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  get_user(user_id: int) -> dict\n  get_permissions(role: str) -> list[str]\n  check_access(user_id: int, resource: str, required_permissions: list[str]) -> bool\n  log_audit(user_id: int, action: str, resource: str, allowed: bool) -> None\n\nTask: For user_id=42, check if they can access the resource \"financial_reports\".\nThe required permissions for that resource are [\"read\", \"finance_view\"].\nSteps:\n1. Get user info (returns {\"name\": \"Alice\", \"role\": \"finance_analyst\"})\n2. Get permissions for their role\n3. Check access against required permissions\n4. Log the audit trail regardless of outcome\n\nShow all 4 tool calls in sequence as JSON.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_004",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_004",
      "expected": "get_user",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "thinking_001_arc_018",
      "task_class": "planning_synthesis",
      "input_payload": "What is the name of the process by which certain bacteria convert atmospheric nitrogen into ammonia?\n\nA) Nitrogen fixation\nB) Nitrification\nC) Denitrification\nD) Ammonification\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.arc_018",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "arc_018",
      "expected": "A",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "mode_advantage_hard_011_ma_hard_code_006",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Knuth-Morris-Pratt (KMP) string matching algorithm.\n\nWrite two functions:\n1. compute_lps(pattern) - Compute the Longest Proper Prefix Suffix array\n2. kmp_search(text, pattern) - Find all occurrences of pattern in text\n\nReturn a list of starting indices where the pattern is found.\n\nExample:\nkmp_search(\"ABABDABACDABABCABAB\", \"ABABCABAB\")\nExpected: [10]\n\nWrite complete Python implementations.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_006",
      "expected": "def kmp_search",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_005_bfcl_010",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef schedule_task(name: str, cron_expression: str, command: str, enabled: bool = True) -> dict:\n    \"\"\"Schedule a recurring task using cron syntax.\n    Args:\n        name: Task name\n        cron_expression: Cron expression (e.g., \"0 9 * * 1-5\")\n        command: Command to execute\n        enabled: Whether task starts enabled\n    \"\"\"\n```\n\nSchedule a daily backup task called \"nightly_backup\" that runs at\n2:30 AM every day and executes the command \"bash /opt/backup.sh\".\nStart it in disabled state.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_010",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_010",
      "expected": "nightly_backup",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_008_code_hard_008",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `dijkstra(graph, start)` that implements\nDijkstra's shortest path algorithm. Graph is a dict of dicts:\n{node: {neighbor: weight}}. Return dict of shortest distances.\n\n>>> graph = {'A': {'B': 1, 'C': 4}, 'B': {'C': 2, 'D': 5}, 'C': {'D': 1}, 'D': {}}\n>>> dijkstra(graph, 'A')\n{'A': 0, 'B': 1, 'C': 3, 'D': 4}\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_008",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_007_code_hard_007",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `binary_search(lst, target)` that implements\nbinary search on a sorted list. Return the index if found, -1 otherwise.\n\n>>> binary_search([1, 2, 3, 4, 5], 3)\n2\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_007",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    }
  ],
  "selected_task_ids": [
    "agentic_007_bfcl_026",
    "mode_advantage_hard_008_ma_hard_code_013",
    "coder_002_code_hard_002",
    "mode_advantage_hard_003_ma_hard_code_003",
    "coder_010_coder_ma_002",
    "agentic_001_agentic_ma_002",
    "coder_004_code_hard_004",
    "mode_advantage_hard_006_ma_hard_code_009",
    "mode_advantage_hard_002_ma_hard_code_002",
    "mode_advantage_hard_009_ma_hard_code_015",
    "coder_013_code_hard_011",
    "coder_003_code_hard_003",
    "thinking_005_logic_004",
    "long_context_004_needle_007",
    "mode_advantage_hard_007_ma_hard_code_011",
    "agentic_004_bfcl_009",
    "coder_005_code_hard_005",
    "long_context_003_needle_006",
    "coder_011_coder_ma_004",
    "agentic_009_bfcl_028",
    "long_context_001_lc_ma_002",
    "thinking_004_logic_003",
    "mode_advantage_hard_014_ma_hard_code_012",
    "coder_012_code_hard_010",
    "long_context_005_needle_008",
    "long_context_002_lc_ma_004",
    "coder_015_coder_ma_003",
    "agentic_010_bfcl_029",
    "mode_advantage_hard_004_ma_hard_code_005",
    "mode_advantage_hard_012_ma_hard_code_008",
    "mode_advantage_hard_001_ma_hard_code_001",
    "mode_advantage_hard_005_ma_hard_code_007",
    "mode_advantage_hard_015_ma_hard_code_014",
    "thinking_003_arc_020",
    "mode_advantage_hard_010_ma_hard_code_004",
    "agentic_006_bfcl_025",
    "agentic_008_bfcl_027",
    "thinking_002_arc_019",
    "mode_advantage_hard_013_ma_hard_code_010",
    "coder_001_code_hard_001",
    "coder_009_code_hard_009",
    "coder_014_coder_ma_001",
    "agentic_003_bfcl_008",
    "coder_006_code_hard_006",
    "agentic_002_agentic_ma_004",
    "thinking_001_arc_018",
    "mode_advantage_hard_011_ma_hard_code_006",
    "agentic_005_bfcl_010",
    "coder_008_code_hard_008",
    "coder_007_code_hard_007"
  ],
  "required_environments": [
    "codex",
    "claude-code"
  ],
  "required_arms": [
    "A",
    "B"
  ]
}
