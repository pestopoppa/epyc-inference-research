{
  "schema_version": 1,
  "created_at": "2026-02-22T00:49:03.886605+00:00",
  "optimization_id": "__bundle__",
  "seed": 215,
  "tasks_per_arm": 100,
  "workload_pack_path": "benchmarks/root_workload/workload_pack_curated_debug_hard100_v1.json",
  "workload_pack_version": "curated-debug-hard100-v1",
  "selected_tasks": [
    {
      "task_id": "coder_019_code_hard_007",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `binary_search(lst, target)` that implements\nbinary search on a sorted list. Return the index if found, -1 otherwise.\n\n>>> binary_search([1, 2, 3, 4, 5], 3)\n2\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_007",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_032_code_hard_012",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `celsius_to_fahrenheit(c)` that converts\na temperature from Celsius to Fahrenheit. Return the result as a float.\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_012",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_012",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_008_code_hard_008",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `dijkstra(graph, start)` that implements\nDijkstra's shortest path algorithm. Graph is a dict of dicts:\n{node: {neighbor: weight}}. Return dict of shortest distances.\n\n>>> graph = {'A': {'B': 1, 'C': 4}, 'B': {'C': 2, 'D': 5}, 'C': {'D': 1}, 'D': {}}\n>>> dijkstra(graph, 'A')\n{'A': 0, 'B': 1, 'C': 3, 'D': 4}\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_008",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_020_bfcl_033",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef setup_sharding(cluster: str, shard_key: str, num_shards: int, replication_factor: int = 3) -> bool:\n    \"\"\"Configure database sharding.\"\"\"\n\ndef replicate_data(source: str, destinations: list, replication_mode: str = \"async\") -> bool:\n    \"\"\"Set up data replication.\"\"\"\n```\n\nShard the \"analytics\" cluster across 8 shards using \"user_id\"\nas the shard key with 3 replicas per shard.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_033",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_033",
      "expected": "setup_sharding",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_037_humaneval_007",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `reverse_string(s)` that returns the reverse\nof the input string.\n\n>>> reverse_string(\"hello\")\n\"olleh\"\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_007",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_001_needle_040",
      "task_class": "long_input",
      "input_payload": "The following documents describe a multi-year environmental monitoring project:\n\nDocument 1 - Project Charter (2021):\nThe Great Basin Watershed Monitoring Initiative was established in\nJanuary 2021 to track water quality across 45 monitoring stations\nspanning Nevada, Utah, and eastern California. The project is funded\nby a $12.4 million grant from the National Science Foundation, with\nadditional support from state agencies. Principal Investigator is\nDr. Marlene Vasquez of the University of Nevada, Reno.\n\nDocument 2 - Annual Report (2022):\nDuring the second year of operations, the team deployed autonomous\nsensor arrays at all 45 stations. Key findings include a 15% decline\nin dissolved oxygen levels at stations along the Humboldt River\ncorridor, attributed to increased agricultural runoff. The team\npublished 8 peer-reviewed papers. Station 23, located at Walker\nLake, recorded the highest salinity readings at 14.2 parts per\nthousand. Budget utilization was 87% of projected expenditure.\n\nDocument 3 - Quarterly Update Q2 2023:\nA critical equipment failure at Station 37 (Ruby Lake) on April 17\nresulted in a 6-week data gap. The replacement sensor, model AquaSense\nPro-X7, was installed on May 29 and has been operating normally since.\nThe project received supplemental funding of $2.1 million from the\nEPA to expand monitoring to include microplastic concentrations.\nNew team member Dr. Chen Wei joined from Stanford to lead the\nmicroplastics analysis effort.\n\nDocument 4 - Special Report (Late 2023):\nCross-referencing satellite imagery with ground station data revealed\nthat Station 12 (Pyramid Lake) showed anomalous temperature readings\nbetween June and August 2023, averaging 2.3\u00b0C above historical norms.\nThis correlates with the discovery of a previously unmapped geothermal\nvent 400 meters northeast of the station, confirmed by USGS survey\nteam visit on September 5, 2023.\n\nQuestion: What specific model of replacement sensor was installed at\nStation 37 after the equipment failure?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_040",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_040",
      "expected": "AquaSense Pro-X7",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_015_bfcl_032",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef configure_load_balancer(name: str, backend_servers: list, algorithm: str = \"round_robin\", health_check: dict = None) -> bool:\n    \"\"\"Configure load balancer.\"\"\"\n```\n\nSet up \"api-lb\" with servers 10.0.1.10:8080, 10.0.1.11:8080,\n10.0.1.12:8080, health checking /health every 10 seconds.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_032",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_032",
      "expected": "configure_load_balancer",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_009_agentic_ma_002",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  search_database(query: str, table: str) -> list[dict]\n  aggregate(data: list[dict], group_by: str, metric: str) -> dict\n  format_report(title: str, data: dict, format: str) -> str\n  send_email(to: str, subject: str, body: str) -> bool\n\nTask: Generate a monthly sales report.\n1. Search the \"orders\" table for all orders in January 2024\n2. Aggregate the results by \"product_category\" using metric \"sum:total_amount\"\n3. Format the aggregated data as an HTML report titled \"January 2024 Sales\"\n4. Email the report to \"manager@company.com\" with subject \"Monthly Sales Report\"\n\nShow all 4 tool calls in order as JSON.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_002",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_002",
      "expected": "search_database",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_003_ma_hard_code_001",
      "task_class": "implementation_fix",
      "input_payload": "Implement a solution for the following problem:\n\nGiven a weighted directed graph with N nodes (1 to N) and M edges,\nfind the shortest path from node 1 to node N that uses at most K edges.\nIf no such path exists, return -1.\n\nInput format:\n- First line: N M K\n- Next M lines: u v w (edge from u to v with weight w)\n\nExample:\nInput:\n4 5 2\n1 2 1\n1 3 5\n2 3 1\n2 4 10\n3 4 1\n\nOutput: 3\n(Path: 1\u21922\u21923\u21924 with total weight 3, using 3 edges... wait, that's 3 edges.\n With K=2: 1\u21923\u21924 = 6, 1\u21922\u21924 = 11. Answer should be 6)\n\nActually output: 6\n\nWrite a complete Python solution.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_001",
      "expected": "def solve",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_007_agentic_ma_001",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  fetch_stock_price(ticker: str) -> float\n  calculate(expression: str) -> float\n  send_alert(message: str) -> bool\n\nTask: Check if the stock price of AAPL is more than 10% above $150.\nIf so, send an alert with the message \"AAPL above threshold: $X.XX\"\nwhere X.XX is the actual price.\n\nShow the sequence of 3 tool calls you would make:\n1. First call fetch_stock_price to get the current price\n2. Then calculate to check if price > 150 * 1.10\n3. If yes, call send_alert with the formatted message\n\nRespond with the 3 JSON function calls in order, each on its own line.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_001",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_001",
      "expected": "fetch_stock_price",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_024_mbpp_009",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `longest_common_prefix(strs)` that finds the\nlongest common prefix string amongst an array of strings. Return \"\"\nif there is no common prefix.\n\n>>> longest_common_prefix([\"flower\", \"flow\", \"flight\"])\n\"fl\"\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_009",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_031_mbpp_005",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `roman_to_int(s)` that converts a Roman\nnumeral string to an integer.\n\n>>> roman_to_int(\"MCMXCIV\")\n1994\n>>> roman_to_int(\"III\")\n3\n>>> roman_to_int(\"IV\")\n4\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_005",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_008_ma_hard_code_003",
      "task_class": "implementation_fix",
      "input_payload": "Implement Tarjan's algorithm for finding strongly connected components\nin a directed graph.\n\nGiven:\n- N nodes numbered 0 to N-1\n- List of edges as (from, to) tuples\n\nReturn:\n- List of SCCs, where each SCC is a list of node indices\n- SCCs should be in reverse topological order\n\nExample:\nedges = [(0,1), (1,2), (2,0), (1,3), (3,4), (4,5), (5,3)]\nExpected output: [[3,4,5], [0,1,2]]\n\nWrite a complete Python function `find_sccs(n, edges)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_003",
      "expected": "def find_sccs",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_011_coder_ma_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function that converts a Roman numeral string to an integer.\nSupport I, V, X, L, C, D, M (values 1 to 3999).\n\n```python\ndef roman_to_int(s):\n    \"\"\"Convert Roman numeral string to integer.\"\"\"\n    pass\n```\n\nWrite the complete function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_002",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_006_bfcl_031",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef send_notification(recipients: list, message: str, channels: list = [\"email\"], priority: str = \"normal\") -> bool:\n    \"\"\"Send multi-channel notification.\"\"\"\n```\n\nAlert oncall team (users 101, 102, 103) via Slack and PagerDuty\nwith high priority that the database is down.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_031",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_031",
      "expected": "send_notification",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "long_context_008_needle_034",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe autonomous vehicle program advances self-driving technology using\nlidar, radar, cameras, and ultrasonic sensors providing 360-degree\nawareness. Redundant computing ensures safe operation.\n\nMachine learning models are trained on millions of miles of driving\ndata collected from test fleets in diverse conditions.\n\nThe chief engineer reported that vehicle VIN 5YJSA1E28GF123456\ncompleted 15,847 autonomous miles during Q4 2025 with only 3\ndisengagements, all during heavy rain. This represents a disengagement\nrate of 0.019 per 100 miles.\n\nThe company plans to expand from 50 to 200 test vehicles in 2026.\n\nQuestion: How many autonomous miles did vehicle 5YJSA1E28GF123456 complete?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_034",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_034",
      "expected": "15,847",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_019_bfcl_023",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef resize_image(input_path: str, output_path: str, width: int, height: int) -> bool:\n    \"\"\"Resize an image.\"\"\"\n\ndef convert_image(input_path: str, output_path: str, format: str) -> bool:\n    \"\"\"Convert image format.\"\"\"\n```\n\nConvert /images/photo.png to JPEG format and save as /images/photo.jpg.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_023",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_023",
      "expected": "convert_image",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_018_mbpp_008",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `is_prime(n)` that returns True if n is a\nprime number, False otherwise. Assume n >= 2.\n\n>>> is_prime(7)\nTrue\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_008",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_014_bfcl_025",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef create_backup(sources: list, destination: str, options: dict = None) -> str:\n    \"\"\"Create backup archive.\n    Args:\n        sources: List of paths to backup\n        destination: Backup destination path\n        options: Backup options (exclude_patterns, compression, incremental, encryption)\n    \"\"\"\n```\n\nCreate an incremental encrypted backup of /home and /etc to\n/backup/daily.tar.gz, excluding .cache and .tmp directories.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_025",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_025",
      "expected": "create_backup",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_036_code_hard_011",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `group_anagrams(words)` that takes a list of\nstrings and groups anagrams together. Return a list of lists, where\neach inner list contains words that are anagrams of each other.\nOrder within groups doesn't matter.\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_011",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_011",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_001_ma_hard_code_006",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Knuth-Morris-Pratt (KMP) string matching algorithm.\n\nWrite two functions:\n1. compute_lps(pattern) - Compute the Longest Proper Prefix Suffix array\n2. kmp_search(text, pattern) - Find all occurrences of pattern in text\n\nReturn a list of starting indices where the pattern is found.\n\nExample:\nkmp_search(\"ABABDABACDABABCABAB\", \"ABABCABAB\")\nExpected: [10]\n\nWrite complete Python implementations.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_006",
      "expected": "def kmp_search",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_002_logic_018",
      "task_class": "planning_synthesis",
      "input_payload": "Consider the statement: \"This statement is false.\" What type of logical construct is this?\n\nA) Tautology\nB) Contradiction\nC) Paradox\nD) Contingency\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_018",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_018",
      "expected": "C",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "long_context_003_needle_032",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe materials science laboratory develops advanced alloys for\naerospace applications. Research combines computational modeling\nwith experimental synthesis and testing.\n\nAdditive manufacturing enables complex geometries. Powder bed fusion\nuses lasers to selectively melt metal powders layer by layer.\n\nThe research team reported in Metallurgical Transactions that titanium\nalloy Ti-6.2Al-4.1V-1.8Mo-0.5Fe achieved an ultimate tensile strength\nof 1,247 MPa after heat treatment at 850C for 4 hours followed by\naging at 550C for 8 hours.\n\nFatigue testing demonstrated integrity through 10^7 cycles at stress\namplitudes up to 70% of ultimate tensile strength.\n\nQuestion: What ultimate tensile strength did the titanium alloy achieve?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_032",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_032",
      "expected": "1,247 MPa",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_013_bfcl_039",
      "task_class": "planning_synthesis",
      "input_payload": "Available function:\n  schedule_pipeline(name: str, stages: list[dict], cron: str,\n                    notify_on_failure: bool, retry_count: int) -> dict\n\nUser request: \"Create a pipeline called 'nightly-etl' that runs\nat midnight daily. It has three stages: extract from source_db,\ntransform with dedup rules, load to warehouse_db. Enable failure\nnotifications and allow 2 retries.\"\n\nRespond with a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_039",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_039",
      "expected": "",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_028_mbpp_014",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `two_sum(nums, target)` that finds two numbers\nin the list that add up to the target. Return their indices as a tuple.\nAssume exactly one solution exists.\n\n>>> two_sum([2, 7, 11, 15], 9)\n(0, 1)\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_014",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_014",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_001_humaneval_012",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `find_min(lst)` that returns the minimum\nelement in a non-empty list of numbers.\n\n>>> find_min([3, 1, 4, 1, 5])\n1\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_012",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_012",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_018_bfcl_028",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef create_alert(name: str, condition: str, actions: list, severity: str = \"warning\") -> int:\n    \"\"\"Create monitoring alert.\"\"\"\n\ndef create_dashboard(name: str, widgets: list, refresh_interval: int = 60) -> int:\n    \"\"\"Create monitoring dashboard.\"\"\"\n```\n\nSet up a critical alert named \"High CPU\" that triggers when CPU\nexceeds 90% for 5 minutes, sending notifications to #ops channel.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_028",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_028",
      "expected": "create_alert",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "thinking_004_logic_004",
      "task_class": "planning_synthesis",
      "input_payload": "Five people finished a race. Amy finished before Ben. Charlie\nfinished after Diana. Ben finished before Diana. Evan finished\nlast. What is the minimum possible position for Charlie?\n\nA) 2nd\nB) 3rd\nC) 4th\nD) 5th\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_004",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_004",
      "expected": "C",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "long_context_002_needle_029",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe pharmaceutical company conducts Phase III clinical trials for a\nnovel oncology therapeutic across 85 sites in 15 countries with 2,400\npatients. Primary endpoints: progression-free survival and response rate.\n\nMolecular profiling identifies genetic markers predicting treatment\nresponse. Next-generation sequencing analyzes hundreds of genes.\n\nThe trial statistician reported in the interim analysis that the\nexperimental arm showed a hazard ratio of 0.64 (95% CI: 0.51-0.79,\np<0.001) compared to standard of care. This exceeded the pre-specified\nefficacy boundary for early success.\n\nManufacturing scale-up is underway to ensure drug supply if approved.\n\nQuestion: What hazard ratio was observed in the interim analysis?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_029",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_029",
      "expected": "0.64",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_021_humaneval_001",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `has_close_elements(numbers, threshold)` that\nchecks whether any two numbers in the list are closer to each other\nthan the given threshold.\n\n>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\nFalse\n>>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\nTrue\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_001",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_016_code_hard_003",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `min_window(s, t)` that finds the minimum\nwindow substring of s that contains all characters of t. Return \"\"\nif no such window exists.\n\n>>> min_window(\"ADOBECODEBANC\", \"ABC\")\n\"BANC\"\n>>> min_window(\"a\", \"aa\")\n\"\"\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_003",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_010_logic_016",
      "task_class": "planning_synthesis",
      "input_payload": "Four suspects are questioned. Exactly one is guilty. Their statements:\nAlice: \"Bob is guilty.\"\nBob: \"Carol is guilty.\"\nCarol: \"David is guilty.\"\nDavid: \"I am innocent.\"\nThe guilty person lies; all innocent people tell the truth. Who is guilty?\n\nA) Alice\nB) Bob\nC) Carol\nD) David\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_016",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_016",
      "expected": "C",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "agentic_003_bfcl_027",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef analyze_logs(log_path: str, filters: dict, aggregations: list, time_range: dict = None) -> dict:\n    \"\"\"Analyze log files with complex queries.\"\"\"\n```\n\nAnalyze /var/log/nginx/access.log for the last 24 hours, counting\nrequests by HTTP status code, filtering out health check endpoints.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_027",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_027",
      "expected": "analyze_logs",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_007_ma_hard_code_004",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Aho-Corasick algorithm for multiple pattern matching.\n\nGiven a text and a list of patterns, find all occurrences of any pattern\nin the text. Return a list of (pattern_index, start_position) tuples.\n\nExample:\ntext = \"ushers\"\npatterns = [\"he\", \"she\", \"his\", \"hers\"]\nExpected: [(1, 1), (0, 2), (3, 2)]\n(she at pos 1, he at pos 2, hers at pos 2)\n\nWrite a complete Python implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_004",
      "expected": "def aho_corasick",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_040_humaneval_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `below_zero(operations)` that takes a list\nof deposit and withdrawal operations starting from zero balance.\nReturn True if the balance goes below zero at any point.\n\n>>> below_zero([1, 2, 3])\nFalse\n>>> below_zero([1, 2, -4, 5])\nTrue\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_004",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_004_bfcl_030",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef migrate_database(source_db: str, target_db: str, options: dict) -> bool:\n    \"\"\"Migrate database with transformation.\"\"\"\n\ndef sync_databases(primary_db: str, replica_db: str, mode: str = \"async\") -> bool:\n    \"\"\"Synchronize databases.\"\"\"\n```\n\nMigrate \"users\" and \"orders\" tables from mysql://old-db to\npostgres://new-db, transforming timestamps to UTC, batch size 10000.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_030",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_030",
      "expected": "migrate_database",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_002_agentic_ma_003",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  read_file(path: str) -> str\n  parse_csv(content: str) -> list[dict]\n  calculate(expression: str) -> float\n\nTask: Read the file at \"/data/expenses.csv\", parse it as CSV,\nthen calculate the total of the \"amount\" column.\n\nShow all 3 tool calls in sequence. For the calculate call, assume\nthe parsed data returned amounts [120.50, 85.00, 234.75, 67.25, 193.50].\nGive the total after ####.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_003",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_003",
      "expected": "701.00",
      "tier": 2,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "agentic_017_bfcl_010",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef schedule_task(name: str, cron_expression: str, command: str, enabled: bool = True) -> dict:\n    \"\"\"Schedule a recurring task using cron syntax.\n    Args:\n        name: Task name\n        cron_expression: Cron expression (e.g., \"0 9 * * 1-5\")\n        command: Command to execute\n        enabled: Whether task starts enabled\n    \"\"\"\n```\n\nSchedule a daily backup task called \"nightly_backup\" that runs at\n2:30 AM every day and executes the command \"bash /opt/backup.sh\".\nStart it in disabled state.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_010",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_010",
      "expected": "nightly_backup",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_021_bfcl_035",
      "task_class": "planning_synthesis",
      "input_payload": "Available function:\n  set_alarm(time: str, label: str) -> dict\n\nUser request: \"Set an alarm for 7:30 AM labeled 'Wake Up'.\"\n\nRespond with a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_035",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_035",
      "expected": "",
      "tier": 1,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_006_mbpp_007",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `prime_factors(n)` that returns a list of\nprime factors of n in ascending order. Assume n > 1.\n\n>>> prime_factors(12)\n[2, 2, 3]\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_007",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_029_mbpp_012",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `find_missing_number(lst)` that finds the\nmissing number in a list containing n distinct numbers in the range\n[0, n]. The list has exactly one number missing.\n\n>>> find_missing_number([0, 1, 3])\n2\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_012",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_012",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_041_coder_ma_003",
      "task_class": "implementation_fix",
      "input_payload": "What does this code print? Trace through carefully.\n\n```python\ndef f(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n <= 1:\n        return n\n    memo[n] = f(n-1, memo) + f(n-2, memo)\n    return memo[n]\n\nresults = []\nfor x in [10, 5, 15]:\n    results.append(f(x))\nprint(results[0], results[1], results[2])\n```\n\nGive the exact output after ####.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_003",
      "expected": "55 5 610",
      "tier": 2,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "coder_017_code_hard_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `longest_palindromic_substring(s)` that finds\nthe longest palindromic substring in s.\n\n>>> longest_palindromic_substring(\"babad\")\n\"bab\"  # or \"aba\"\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_004",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_014_humaneval_009",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `factorial(n)` that computes n! (n factorial).\nAssume n >= 0.\n\n>>> factorial(5)\n120\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_009",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_005_bfcl_029",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef execute_workflow(workflow_def: dict, inputs: dict, options: dict = None) -> str:\n    \"\"\"Execute multi-step workflow.\"\"\"\n```\n\nRun a workflow: 1) pull latest code, 2) run tests, 3) build docker\nimage if tests pass, 4) deploy to staging, with 30-min timeout.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_029",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_029",
      "expected": "execute_workflow",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_035_humaneval_006",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `is_even(n)` that returns True if n is even,\nFalse otherwise.\n\n>>> is_even(4)\nTrue\n>>> is_even(7)\nFalse\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_006",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_005_mbpp_003",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `most_frequent(lst)` that returns the most\nfrequently occurring element in a list. If there's a tie, return\nany of the most frequent elements.\n\n>>> most_frequent([1, 2, 2, 3, 3, 3])\n3\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_003",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_009_ma_hard_code_009",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Hungarian algorithm for the assignment problem.\n\nGiven an N\u00d7N cost matrix, find the assignment of workers to jobs\nthat minimizes total cost. Each worker is assigned exactly one job\nand each job is assigned exactly one worker.\n\nReturn the minimum total cost and the assignment as a list where\nassignment[i] is the job assigned to worker i.\n\nExample:\ncost = [[9, 2, 7, 8],\n        [6, 4, 3, 7],\n        [5, 8, 1, 8],\n        [7, 6, 9, 4]]\nExpected minimum cost: 13 (assignments: 0\u21921, 1\u21922, 2\u21922... wait)\n\nWrite `def hungarian(cost_matrix)` returning (min_cost, assignment).\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_009",
      "expected": "def hungarian",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_013_humaneval_003",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `truncate_number(number)` that returns the\ndecimal part of a positive floating point number.\n\n>>> truncate_number(3.5)\n0.5\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_003",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_003",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_042_coder_ma_001",
      "task_class": "implementation_fix",
      "input_payload": "The following function is supposed to implement run-length encoding\nbut produces wrong output. Fix it.\n\n```python\ndef rle_encode(s):\n    if not s:\n        return \"\"\n    result = []\n    count = 1\n    for i in range(1, len(s)):\n        if s[i] == s[i-1]:\n            count += 1\n        else:\n            result.append(f\"{count}{s[i]}\")\n            count = 1\n    result.append(f\"{count}{s[-1]}\")\n    return \"\".join(result)\n```\n\nWrite the corrected function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_001",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_025_humaneval_015",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `flatten_list(lst)` that flattens a nested\nlist one level deep.\n\n>>> flatten_list([[1, 2], [3, 4]])\n[1, 2, 3, 4]\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_015",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_015",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_038_mbpp_001",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `is_palindrome(s)` that checks if a string\nis a palindrome, ignoring case and non-alphanumeric characters.\n\n>>> is_palindrome(\"A man, a plan, a canal: Panama\")\nTrue\n>>> is_palindrome(\"race a car\")\nFalse\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_001",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_011_ma_hard_code_014",
      "task_class": "implementation_fix",
      "input_payload": "Implement a LRU (Least Recently Used) cache with O(1) operations:\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        pass\n\n    def get(self, key: int) -> int:\n        # Return value if exists, -1 otherwise\n        # Mark as recently used\n\n    def put(self, key: int, value: int) -> None:\n        # Insert or update key-value\n        # Evict LRU item if at capacity\n\nMust use O(1) time for both get and put.\n\nWrite a complete Python implementation using OrderedDict or\na combination of dict and doubly-linked list.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_014",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_014",
      "expected": "class LRUCache",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_012_humaneval_008",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `count_vowels(s)` that counts the number of\nvowels (a, e, i, o, u) in a string, case-insensitive.\n\n>>> count_vowels(\"hello\")\n2\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_008",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_006_needle_035",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe smart city initiative integrates sensors and analytics to improve\nurban services. Infrastructure includes traffic cameras, air quality\nsensors, smart streetlights, and waste management systems.\n\nTraffic management adjusts signal timing based on congestion patterns.\nEnvironmental monitoring tracks pollutants including PM, ozone, and NO2.\n\nThe city's environmental dashboard shows sensor station ENV-082-Downtown\nrecorded a PM2.5 concentration of 45.7 micrograms per cubic meter at\n08:00 on January 20, 2026. This exceeded the daily exposure guideline\nand triggered an air quality alert.\n\nSource analysis indicated the elevated levels were primarily from\nvehicle emissions combined with temperature inversion conditions.\n\nQuestion: What PM2.5 concentration was recorded at sensor ENV-082-Downtown?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_035",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_035",
      "expected": "45.7 micrograms per cubic meter",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_010_bfcl_040",
      "task_class": "planning_synthesis",
      "input_payload": "Available function:\n  configure_cdn(domain: str, origin: str, cache_ttl: int,\n                 ssl: bool, edge_locations: list[str]) -> dict\n\nUser request: \"Set up CDN for assets.example.com with origin at\norigin.example.com. Cache for 3600 seconds, enable SSL, and deploy\nto edge locations us-east-1, eu-west-1, and ap-southeast-1.\"\n\nRespond with a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_040",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_040",
      "expected": "",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_026_mbpp_011",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `rotate_list(lst, k)` that rotates a list\nto the right by k positions.\n\n>>> rotate_list([1, 2, 3, 4, 5], 2)\n[4, 5, 1, 2, 3]\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_011",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_011",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_001_bfcl_008",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n```\ndef query_database(table: str, conditions: dict, columns: list = [], limit: int = 100) -> list:\n    \"\"\"Query a database table.\n    Args:\n        table: Table name\n        conditions: WHERE conditions as key-value pairs\n        columns: Columns to select (empty = all)\n        limit: Max rows to return\n    \"\"\"\n```\n\nFind the first 5 users from the \"users\" table who are located in\n\"New York\" and have status \"active\". Only return their name and email.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_008",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_008",
      "expected": "query_database",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_012_ma_hard_code_011",
      "task_class": "implementation_fix",
      "input_payload": "Implement Dijkstra's algorithm with a Fibonacci heap for O(E + V log V)\ncomplexity. If Fibonacci heap is too complex, use a standard heap but\ndocument the complexity difference.\n\nGiven:\n- Number of vertices V\n- List of edges as (u, v, weight) tuples\n- Source vertex s\n\nReturn:\n- Dictionary mapping each vertex to its shortest distance from s\n- Dictionary mapping each vertex to its predecessor in the shortest path\n\nWrite `def dijkstra(V, edges, source)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_011",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_011",
      "expected": "def dijkstra",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_005_logic_005",
      "task_class": "planning_synthesis",
      "input_payload": "A bat and a ball cost $1.10 in total. The bat costs $1.00 more than\nthe ball. How much does the ball cost?\n\nA) $0.10\nB) $0.05\nC) $0.01\nD) $0.15\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_005",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_005",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "coder_023_humaneval_014",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `multiply_list(lst)` that returns the product\nof all elements in a list of numbers. Return 1 for an empty list.\n\n>>> multiply_list([2, 3, 4])\n24\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_014",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_014",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_007_mbpp_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `merge_sorted(lst1, lst2)` that merges two\nsorted lists into a single sorted list without using the built-in\nsort function.\n\n>>> merge_sorted([1, 3, 5], [2, 4, 6])\n[1, 2, 3, 4, 5, 6]\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_004",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_002_mbpp_010",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `merge_sorted_lists(lst1, lst2)` that merges\ntwo sorted lists into one sorted list.\n\n>>> merge_sorted_lists([1, 3, 5], [2, 4, 6])\n[1, 2, 3, 4, 5, 6]\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_010",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_007_logic_017",
      "task_class": "planning_synthesis",
      "input_payload": "You have 12 identical-looking coins, one of which is counterfeit (either heavier or lighter). Using a balance scale exactly three times, can you always identify the counterfeit coin and determine if it is heavier or lighter?\n\nA) Yes, it is always possible\nB) No, you need at least four weighings\nC) Yes, but only if the counterfeit is heavier\nD) Yes, but you cannot determine if it is heavier or lighter\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_017",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_017",
      "expected": "A",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "coder_034_mbpp_013",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `valid_parentheses(s)` that determines if\na string of parentheses (), {}, [] is valid. Valid means each opening\nbracket has a corresponding closing bracket in the correct order.\n\n>>> valid_parentheses(\"()[]{}\")\nTrue\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_013",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_013",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_004_needle_007",
      "task_class": "long_input",
      "input_payload": "Read these three interconnected reports.\n\n=== REPORT A: Sales Summary ===\nQ1 2025 sales by region:\n- North America: $15.3M (lead: Sarah Johnson)\n- Europe: $12.1M (lead: Marco Rossi)\n- Asia Pacific: $18.7M (lead: Yuki Tanaka)\nTotal Q1 2025: $46.1M\n\n=== REPORT B: Regional Strategy ===\nThe highest-performing region in Q1 should receive an additional\n20% budget increase for Q2. The regional lead of the\nhighest-performing region will present at the annual conference.\n\n=== REPORT C: Conference Details ===\nAnnual Sales Conference: July 15-17, 2025, Grand Hotel, Singapore.\nKeynote speaker: CEO Maria Garcia.\nRegional presentation slot: Day 2, 10:00 AM.\n\nQuestion: Based on Q1 2025 performance, who will present at the\nannual conference and in which city will it be held?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_007",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_007",
      "expected": "Yuki Tanaka",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_043_code_hard_006",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `quick_sort(lst)` that implements the quicksort\nalgorithm to sort a list of numbers in ascending order.\n\n>>> quick_sort([3, 6, 8, 10, 1, 2, 1])\n[1, 1, 2, 3, 6, 8, 10]\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_006",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_008_arc_020",
      "task_class": "planning_synthesis",
      "input_payload": "In molecular biology, what is the role of the TATA box?\n\nA) It codes for transfer RNA\nB) It is a promoter sequence for transcription initiation\nC) It signals translation termination\nD) It binds ribosomes directly\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.arc_020",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "arc_020",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "coder_033_humaneval_013",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `remove_duplicates(lst)` that returns a new\nlist with duplicates removed, preserving the original order.\n\n>>> remove_duplicates([1, 2, 2, 3, 1])\n[1, 2, 3]\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_013",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_013",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "agentic_011_agentic_ma_004",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these tools:\n  get_user(user_id: int) -> dict\n  get_permissions(role: str) -> list[str]\n  check_access(user_id: int, resource: str, required_permissions: list[str]) -> bool\n  log_audit(user_id: int, action: str, resource: str, allowed: bool) -> None\n\nTask: For user_id=42, check if they can access the resource \"financial_reports\".\nThe required permissions for that resource are [\"read\", \"finance_view\"].\nSteps:\n1. Get user info (returns {\"name\": \"Alice\", \"role\": \"finance_analyst\"})\n2. Get permissions for their role\n3. Check access against required permissions\n4. Log the audit trail regardless of outcome\n\nShow all 4 tool calls in sequence as JSON.\n",
      "quality_rubric_id": "rubric.debug.agentic.agentic_ma_004",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "agentic_ma_004",
      "expected": "get_user",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_020_code_hard_005",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `permutations(lst)` that generates all\npermutations of a list. Return as a list of lists.\n\n>>> sorted(permutations([1, 2, 3]))\n[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]]\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_005",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_001_logic_006",
      "task_class": "planning_synthesis",
      "input_payload": "If you overtake the person in 2nd place in a race, what position\nare you in?\n\nA) 1st place\nB) 2nd place\nC) 3rd place\nD) It depends on when you overtook them\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_006",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_006",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "mode_advantage_hard_015_ma_hard_code_015",
      "task_class": "implementation_fix",
      "input_payload": "Implement a suffix array construction algorithm with O(n log n) complexity.\n\nGiven a string s, compute:\n1. The suffix array (indices of sorted suffixes)\n2. The LCP (Longest Common Prefix) array\n\nExample:\ns = \"banana\"\nsuffix_array = [5, 3, 1, 0, 4, 2]\n(suffixes: \"a\", \"ana\", \"anana\", \"banana\", \"na\", \"nana\" sorted)\nlcp_array = [1, 3, 0, 0, 2]\n\nWrite `def build_suffix_array(s)` returning (suffix_array, lcp_array).\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_015",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_015",
      "expected": "def build_suffix_array",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_006_ma_hard_code_005",
      "task_class": "implementation_fix",
      "input_payload": "Implement a segment tree with lazy propagation that supports:\n1. Range update: Add value v to all elements in range [l, r]\n2. Range query: Find sum of elements in range [l, r]\n\nBoth operations must be O(log n).\n\nExample:\narr = [1, 3, 5, 7, 9, 11]\ntree = SegmentTree(arr)\ntree.range_query(1, 3)  # Returns 15 (3+5+7)\ntree.range_update(1, 3, 10)  # Add 10 to indices 1,2,3\ntree.range_query(1, 3)  # Returns 45 (13+15+17)\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_005",
      "expected": "class SegmentTree",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_002_ma_hard_code_002",
      "task_class": "implementation_fix",
      "input_payload": "Implement a lock-free stack using compare-and-swap (CAS) operations.\n\nThe stack must handle the ABA problem correctly using either:\n1. Hazard pointers, or\n2. Tagged pointers with version numbers\n\nRequirements:\n- push(value): Add value to top of stack\n- pop(): Remove and return top value, or None if empty\n- Must be thread-safe without using locks\n\nWrite a Python implementation using atomics from the `atomics` library\nor simulate CAS with a lock for demonstration purposes.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_002",
      "expected": "class LockFreeStack",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "agentic_012_bfcl_026",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to:\n\n```\ndef deploy_container(image: str, name: str, ports: dict = None, volumes: dict = None, env: dict = None) -> str:\n    \"\"\"Deploy a container.\"\"\"\n\ndef scale_service(service_name: str, replicas: int) -> bool:\n    \"\"\"Scale service replicas.\"\"\"\n```\n\nLaunch a Redis container named \"cache-01\" mapping port 6379 to\nhost port 6380, mounting /data/redis to /data in the container.\nRespond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_026",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_026",
      "expected": "deploy_container",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_022_coder_ma_004",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function that checks if a given sudoku board is valid.\nThe board is a 9x9 list of lists, with 0 representing empty cells.\nCheck rows, columns, and 3x3 sub-boxes.\n\n```python\ndef is_valid_sudoku(board):\n    \"\"\"Return True if the board state is valid (no conflicts).\"\"\"\n    pass\n```\n\nWrite the complete function.\n",
      "quality_rubric_id": "rubric.debug.coder.coder_ma_004",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "coder_ma_004",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_003_logic_007",
      "task_class": "planning_synthesis",
      "input_payload": "A farmer has 17 sheep. All but 9 die. How many sheep does the\nfarmer have left?\n\nA) 8\nB) 9\nC) 17\nD) 0\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_007",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_007",
      "expected": "B",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "agentic_016_bfcl_009",
      "task_class": "planning_synthesis",
      "input_payload": "You have access to these functions:\n\n```\ndef read_file(path: str) -> str:\n    \"\"\"Read a file's contents.\"\"\"\n\ndef write_file(path: str, content: str) -> bool:\n    \"\"\"Write content to a file.\"\"\"\n\ndef list_directory(path: str, recursive: bool = False) -> list:\n    \"\"\"List files in a directory.\"\"\"\n\ndef execute_command(command: str, timeout: int = 30) -> dict:\n    \"\"\"Execute a shell command.\"\"\"\n```\n\nThe user says: \"List all Python files in the project directory at\n/home/user/project, including subdirectories.\"\n\nChoose the correct function and respond with ONLY a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_009",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_009",
      "expected": "list_directory",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_013_ma_hard_code_013",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Hopcroft-Karp algorithm for maximum bipartite matching.\n\nGiven a bipartite graph with left vertices 0..n-1 and right vertices 0..m-1,\nand a list of edges, find the maximum matching.\n\nReturn:\n- Size of maximum matching\n- List of (left, right) pairs in the matching\n\nTime complexity should be O(E\u221aV).\n\nWrite `def hopcroft_karp(n, m, edges)`.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_013",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_013",
      "expected": "def hopcroft_karp",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_044_code_hard_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `eval_rpn(tokens)` that evaluates a\nmathematical expression in Reverse Polish Notation. The tokens are\na list of strings, where each string is either an integer or one of\n'+', '-', '*', '/'. Division truncates toward zero.\n\n>>> eval_rpn([\"2\", \"1\", \"+\", \"3\", \"*\"])\n9\n>>> eval_rpn([\"4\", \"13\", \"5\", \"/\", \"+\"])\n6\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_002",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_004_code_hard_010",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `is_balanced(s)` that checks if a string\ncontaining only '(', ')', '{', '}', '[', ']' has balanced brackets.\nReturn True if balanced, False otherwise.\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_010",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_014_ma_hard_code_012",
      "task_class": "implementation_fix",
      "input_payload": "Implement a Bloom filter with the following interface:\n\nclass BloomFilter:\n    def __init__(self, capacity: int, error_rate: float):\n        # Initialize with expected capacity and desired false positive rate\n\n    def add(self, item: str) -> None:\n        # Add an item to the filter\n\n    def __contains__(self, item: str) -> bool:\n        # Return True if item might be in set, False if definitely not\n\nUse optimal number of hash functions: k = (m/n) * ln(2)\nwhere m = bits, n = capacity.\n\nWrite a complete Python implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_012",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_012",
      "expected": "class BloomFilter",
      "tier": 2,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_003_mbpp_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `flatten(lst)` that takes a nested list and\nreturns a flat list. Handle arbitrary nesting depth.\n\n>>> flatten([1, [2, [3, 4], 5], 6])\n[1, 2, 3, 4, 5, 6]\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_002",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_004_ma_hard_code_008",
      "task_class": "implementation_fix",
      "input_payload": "Implement the Floyd-Warshall algorithm for all-pairs shortest paths.\n\nGiven an adjacency matrix where matrix[i][j] is the weight of edge i\u2192j\n(or float('inf') if no edge), compute the shortest path between all pairs.\n\nAlso detect if there's a negative cycle (return None in that case).\n\nExample:\nmatrix = [\n  [0, 3, float('inf'), 5],\n  [2, 0, float('inf'), 4],\n  [float('inf'), 1, 0, float('inf')],\n  [float('inf'), float('inf'), 2, 0]\n]\n\nWrite `def floyd_warshall(matrix)` returning the distance matrix.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_008",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_008",
      "expected": "def floyd_warshall",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_009_humaneval_005",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `max_element(lst)` that returns the maximum\nelement in a non-empty list of integers.\n\n>>> max_element([1, 5, 3, 2])\n5\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_005",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_005",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "long_context_010_needle_028",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe renewable energy company develops solar, wind, and storage\nfacilities with combined capacity exceeding 5 gigawatts. Advanced\nforecasting models predict energy production based on weather.\n\nEnergy storage uses lithium-ion batteries to balance supply/demand.\nGrid-scale facilities discharge at rates up to 500 megawatts.\n\nIn the quarterly earnings report, the CFO noted the Sonora Desert\nsolar facility generated 847,293 megawatt-hours in Q3 2025, exceeding\nprojections by 12%. The facility uses bifacial solar panels on\nsingle-axis tracking systems.\n\nFuture plans include adding 2 gigawatts of additional capacity by 2028.\n\nQuestion: How many megawatt-hours did the Sonora Desert facility generate?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_028",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_028",
      "expected": "847,293",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "mode_advantage_hard_010_ma_hard_code_010",
      "task_class": "implementation_fix",
      "input_payload": "Implement a trie (prefix tree) with the following methods:\n1. insert(word): Add a word to the trie\n2. search(word): Return True if word exists\n3. starts_with(prefix): Return True if any word starts with prefix\n4. autocomplete(prefix, limit): Return up to `limit` words with given prefix\n\nThe autocomplete should return words in lexicographic order.\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_010",
      "expected": "class Trie",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "mode_advantage_hard_005_ma_hard_code_007",
      "task_class": "implementation_fix",
      "input_payload": "Implement a Treap (tree + heap) data structure with:\n1. insert(key, priority): Insert a key with given priority\n2. delete(key): Remove a key from the treap\n3. search(key): Return True if key exists\n4. The tree must maintain BST property on keys and max-heap on priorities\n\nRotations must be used to maintain the heap property.\n\nWrite a complete Python class implementation.\n",
      "quality_rubric_id": "rubric.debug.mode_advantage_hard.ma_hard_code_007",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/mode_advantage_hard.yaml",
      "source_key": "ma_hard_code_007",
      "expected": "class Treap",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "long_context_005_lc_ma_002",
      "task_class": "long_input",
      "input_payload": "Read the following employee database and answer the multi-hop question.\n\nEMPLOYEES:\n| ID  | Name          | Dept    | Manager_ID | Salary | Hire_Date  |\n|-----|---------------|---------|------------|--------|------------|\n| 101 | Sarah Chen    | Eng     | 105        | 125000 | 2019-03-15 |\n| 102 | James Wilson  | Eng     | 105        | 115000 | 2020-06-01 |\n| 103 | Maria Garcia  | Sales   | 106        | 95000  | 2018-11-20 |\n| 104 | David Kim     | Sales   | 106        | 88000  | 2021-01-10 |\n| 105 | Lisa Park     | Eng     | 110        | 155000 | 2015-08-01 |\n| 106 | Tom Brown     | Sales   | 110        | 140000 | 2016-04-22 |\n| 107 | Amy Johnson   | Eng     | 105        | 108000 | 2022-09-15 |\n| 108 | Carlos Ruiz   | HR      | 110        | 98000  | 2019-07-01 |\n| 109 | Priya Patel   | HR      | 108        | 82000  | 2021-03-01 |\n| 110 | Robert Taylor | Exec    | NULL       | 200000 | 2012-01-15 |\n| 111 | Wei Zhang     | Eng     | 105        | 120000 | 2020-02-01 |\n| 112 | Anna Schmidt  | Sales   | 106        | 91000  | 2022-05-10 |\n\nMulti-hop question: What is the total salary of all employees whose manager\nreports directly to Robert Taylor (ID 110)? Do NOT include the managers\nthemselves or Robert Taylor.\n\nGive the total salary after ####.\n",
      "quality_rubric_id": "rubric.debug.long_context.lc_ma_002",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "lc_ma_002",
      "expected": "824000",
      "tier": 3,
      "scoring_method": "exact_match"
    },
    {
      "task_id": "agentic_008_bfcl_034",
      "task_class": "planning_synthesis",
      "input_payload": "Available function:\n  send_email(to: str, subject: str, body: str) -> dict\n\nUser request: \"Send an email to alice@example.com with subject\n'Meeting Tomorrow' and body 'Let's meet at 3 PM'.\"\n\nRespond with a JSON function call.\n",
      "quality_rubric_id": "rubric.debug.agentic.bfcl_034",
      "expected_artifact_type": "plan",
      "source": "benchmarks/prompts/debug/agentic.yaml",
      "source_key": "bfcl_034",
      "expected": "",
      "tier": 1,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_015_humaneval_002",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `separate_paren_groups(paren_string)` that\ntakes a string of nested parentheses and returns a list of separate\nbalanced groups. Ignore spaces.\n\n>>> separate_paren_groups('( ) (( )) (( )( ))')\n['()', '(())', '(()())']\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_002",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_002",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_006_logic_021",
      "task_class": "planning_synthesis",
      "input_payload": "Three boxes are labeled 'Apples', 'Oranges', and 'Mixed'. ALL labels are wrong. You pick one fruit from the box labeled 'Mixed' and get an apple. What does the box labeled 'Oranges' contain?\n\nA) Oranges\nB) Apples\nC) Mixed fruits\nD) Cannot be determined\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.logic_021",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "logic_021",
      "expected": "C",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "long_context_009_needle_027",
      "task_class": "long_input",
      "input_payload": "Read the following passage and answer the question.\n\nThe cybersecurity firm provides threat intelligence and incident\nresponse services. Their SOC operates 24/7, monitoring network\ntraffic and analyzing threats.\n\nMachine learning models detect anomalous behavior patterns. False\npositive rates have been reduced 85% over two years.\n\nDuring forensic investigation of a client breach in November 2025,\nthe analysis team identified the initial compromise through a\nspear-phishing email sent to employee ID EMP-5583. The email\ncontained a malicious PDF exploiting a zero-day vulnerability.\n\nThe attacker gained access on October 28 at 09:17 UTC and maintained\npersistence through a custom backdoor using DNS tunneling. The\nbackdoor remained undetected for 12 days.\n\nQuestion: What employee ID was targeted in the spear-phishing attack?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_027",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_027",
      "expected": "EMP-5583",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "long_context_007_needle_006",
      "task_class": "long_input",
      "input_payload": "Read the following company documents carefully. You will need to\ncombine information from multiple sections.\n\n=== DOCUMENT 1: Employee Directory ===\n- Alice Chen: Engineering Manager, Team Alpha, Office 301\n- Bob Kumar: Senior Engineer, Team Beta, Office 412\n- Carol Davis: Product Manager, Team Alpha, Office 303\n- David Lee: Junior Engineer, Team Alpha, Office 305\n- Eve Wilson: Senior Engineer, Team Alpha, Office 302\n\n=== DOCUMENT 2: Team Assignments ===\nTeam Alpha is working on Project Phoenix. The team lead is Alice Chen.\nTeam Beta is working on Project Mercury. The team lead is Frank Martinez.\nProject Phoenix has a deadline of March 2026.\nProject Mercury has a deadline of June 2026.\n\n=== DOCUMENT 3: Budget Allocations ===\nProject Phoenix: $1.2M (Q1: $400K, Q2: $500K, Q3: $300K)\nProject Mercury: $800K (Q1: $300K, Q2: $300K, Q3: $200K)\nThe Project Phoenix technical reviewer is Eve Wilson.\n\nQuestion: Who is the technical reviewer for the project that\nDavid Lee is working on, and what is that project's Q2 budget?\n",
      "quality_rubric_id": "rubric.debug.long_context.needle_006",
      "expected_artifact_type": "summary",
      "source": "benchmarks/prompts/debug/long_context.yaml",
      "source_key": "needle_006",
      "expected": "Eve Wilson",
      "tier": 3,
      "scoring_method": "substring"
    },
    {
      "task_id": "coder_010_mbpp_006",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `fibonacci(n)` that returns the nth Fibonacci\nnumber. F(0) = 0, F(1) = 1, F(n) = F(n-1) + F(n-2) for n >= 2.\n\n>>> fibonacci(6)\n8\n",
      "quality_rubric_id": "rubric.debug.coder.mbpp_006",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "mbpp_006",
      "expected": "",
      "tier": 2,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "thinking_009_arc_018",
      "task_class": "planning_synthesis",
      "input_payload": "What is the name of the process by which certain bacteria convert atmospheric nitrogen into ammonia?\n\nA) Nitrogen fixation\nB) Nitrification\nC) Denitrification\nD) Ammonification\n\nAnswer with the letter only (A, B, C, or D).\n",
      "quality_rubric_id": "rubric.debug.thinking.arc_018",
      "expected_artifact_type": "analysis",
      "source": "benchmarks/prompts/debug/thinking.yaml",
      "source_key": "arc_018",
      "expected": "A",
      "tier": 3,
      "scoring_method": "multiple_choice"
    },
    {
      "task_id": "coder_030_code_hard_009",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `matrix_multiply(A, B)` that multiplies two\nmatrices represented as lists of lists. Return the resulting matrix.\nAssume dimensions are compatible (A is m\u00d7n, B is n\u00d7p).\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_009",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_009",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_039_humaneval_010",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `sum_list(lst)` that returns the sum of all\nelements in a list of numbers.\n\n>>> sum_list([1, 2, 3, 4])\n10\n",
      "quality_rubric_id": "rubric.debug.coder.humaneval_010",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "humaneval_010",
      "expected": "",
      "tier": 1,
      "scoring_method": "code_execution"
    },
    {
      "task_id": "coder_027_code_hard_001",
      "task_class": "implementation_fix",
      "input_payload": "Write a Python function `longest_common_subsequence(s1, s2)` that\nreturns the length of the longest common subsequence of two strings.\n\n>>> longest_common_subsequence(\"abcde\", \"ace\")\n3\n>>> longest_common_subsequence(\"abc\", \"def\")\n0\n",
      "quality_rubric_id": "rubric.debug.coder.code_hard_001",
      "expected_artifact_type": "code",
      "source": "benchmarks/prompts/debug/coder.yaml",
      "source_key": "code_hard_001",
      "expected": "",
      "tier": 3,
      "scoring_method": "code_execution"
    }
  ],
  "selected_task_ids": [
    "coder_019_code_hard_007",
    "coder_032_code_hard_012",
    "coder_008_code_hard_008",
    "agentic_020_bfcl_033",
    "coder_037_humaneval_007",
    "long_context_001_needle_040",
    "agentic_015_bfcl_032",
    "agentic_009_agentic_ma_002",
    "mode_advantage_hard_003_ma_hard_code_001",
    "agentic_007_agentic_ma_001",
    "coder_024_mbpp_009",
    "coder_031_mbpp_005",
    "mode_advantage_hard_008_ma_hard_code_003",
    "coder_011_coder_ma_002",
    "agentic_006_bfcl_031",
    "long_context_008_needle_034",
    "agentic_019_bfcl_023",
    "coder_018_mbpp_008",
    "agentic_014_bfcl_025",
    "coder_036_code_hard_011",
    "mode_advantage_hard_001_ma_hard_code_006",
    "thinking_002_logic_018",
    "long_context_003_needle_032",
    "agentic_013_bfcl_039",
    "coder_028_mbpp_014",
    "coder_001_humaneval_012",
    "agentic_018_bfcl_028",
    "thinking_004_logic_004",
    "long_context_002_needle_029",
    "coder_021_humaneval_001",
    "coder_016_code_hard_003",
    "thinking_010_logic_016",
    "agentic_003_bfcl_027",
    "mode_advantage_hard_007_ma_hard_code_004",
    "coder_040_humaneval_004",
    "agentic_004_bfcl_030",
    "agentic_002_agentic_ma_003",
    "agentic_017_bfcl_010",
    "agentic_021_bfcl_035",
    "coder_006_mbpp_007",
    "coder_029_mbpp_012",
    "coder_041_coder_ma_003",
    "coder_017_code_hard_004",
    "coder_014_humaneval_009",
    "agentic_005_bfcl_029",
    "coder_035_humaneval_006",
    "coder_005_mbpp_003",
    "mode_advantage_hard_009_ma_hard_code_009",
    "coder_013_humaneval_003",
    "coder_042_coder_ma_001",
    "coder_025_humaneval_015",
    "coder_038_mbpp_001",
    "mode_advantage_hard_011_ma_hard_code_014",
    "coder_012_humaneval_008",
    "long_context_006_needle_035",
    "agentic_010_bfcl_040",
    "coder_026_mbpp_011",
    "agentic_001_bfcl_008",
    "mode_advantage_hard_012_ma_hard_code_011",
    "thinking_005_logic_005",
    "coder_023_humaneval_014",
    "coder_007_mbpp_004",
    "coder_002_mbpp_010",
    "thinking_007_logic_017",
    "coder_034_mbpp_013",
    "long_context_004_needle_007",
    "coder_043_code_hard_006",
    "thinking_008_arc_020",
    "coder_033_humaneval_013",
    "agentic_011_agentic_ma_004",
    "coder_020_code_hard_005",
    "thinking_001_logic_006",
    "mode_advantage_hard_015_ma_hard_code_015",
    "mode_advantage_hard_006_ma_hard_code_005",
    "mode_advantage_hard_002_ma_hard_code_002",
    "agentic_012_bfcl_026",
    "coder_022_coder_ma_004",
    "thinking_003_logic_007",
    "agentic_016_bfcl_009",
    "mode_advantage_hard_013_ma_hard_code_013",
    "coder_044_code_hard_002",
    "coder_004_code_hard_010",
    "mode_advantage_hard_014_ma_hard_code_012",
    "coder_003_mbpp_002",
    "mode_advantage_hard_004_ma_hard_code_008",
    "coder_009_humaneval_005",
    "long_context_010_needle_028",
    "mode_advantage_hard_010_ma_hard_code_010",
    "mode_advantage_hard_005_ma_hard_code_007",
    "long_context_005_lc_ma_002",
    "agentic_008_bfcl_034",
    "coder_015_humaneval_002",
    "thinking_006_logic_021",
    "long_context_009_needle_027",
    "long_context_007_needle_006",
    "coder_010_mbpp_006",
    "thinking_009_arc_018",
    "coder_030_code_hard_009",
    "coder_039_humaneval_010",
    "coder_027_code_hard_001"
  ],
  "required_environments": [
    "codex",
    "claude-code"
  ],
  "required_arms": [
    "A",
    "B"
  ]
}
